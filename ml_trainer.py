# ml_trainer.py
import pandas as pd
import numpy as np
import logging
import joblib
import time
import json
from datetime import datetime
from pathlib import Path
from config import SYMBOL, TRADING_MODE
from data import fetch_ohlcv
from indicators import add_indicators
from utils_ml import load_real_trades_as_labels
from risk_manager import calculate_position_size
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from sklearn.utils.class_weight import compute_class_weight

def create_features_and_labels(df, lookahead=10, threshold=0.015):
    """
    Crea features (X) y etiquetas (y) para entrenamiento.
    """
    df = df.copy()
    
    # ‚úÖ A√ëADIR INDICADORES PRIMERO
    df = add_indicators(df)
    
    # Calcular retorno futuro
    df['future_close'] = df['close'].shift(-lookahead)
    df['future_return'] = (df['future_close'] - df['close']) / df['close']
    
    # Etiquetas
    df['label'] = 0
    df.loc[df['future_return'] > threshold, 'label'] = 1    # Long
    df.loc[df['future_return'] < -threshold, 'label'] = -1  # Short
    
    # Eliminar NaN
    df = df.dropna()
    
    # Features
    feature_cols = [
        'open', 'high', 'low', 'close', 'volume',
        'ema50', 'ema200', 'rsi', 'atr',
        'upper_wick', 'lower_wick', 'body',
        'liquidez'
    ]
    
    # ‚úÖ VERIFICAR QUE TODAS LAS COLUMNAS EXISTAN
    missing_cols = [col for col in feature_cols if col not in df.columns]
    if missing_cols:
        logging.warning(f"‚ö†Ô∏è Columnas faltantes en el DataFrame: {missing_cols}")
        # Filtrar solo columnas existentes
        feature_cols = [col for col in feature_cols if col in df.columns]
    
    X = df[feature_cols]
    y = df['label']
    
    return X, y, feature_cols

def train_ml_model(symbol="BTC/USDT:USDT", days=30):
    print("üì• Descargando datos hist√≥ricos...")
    df = fetch_ohlcv(symbol, "1h", limit=24*days)
    
    if df.empty:
        print("‚ùå Error al cargar datos.")
        return
    
    # ‚úÖ VERIFICAR ESTRUCTURA DEL DATAFRAME
    print(f"üîç Estructura inicial del DataFrame:")
    print(f"  - Columnas disponibles: {list(df.columns)}")
    print(f"  - Tama√±o: {df.shape}")
    
    # ‚úÖ FORZAR A√ëADIR INDICADORES DESDE EL PRINCIPIO
    df = add_indicators(df)
    print(f"üìä Columnas despu√©s de a√±adir indicadores: {list(df.columns)}")
    
    print("‚öôÔ∏è  Creando features y etiquetas...")
    X, y, feature_cols = create_features_and_labels(df, lookahead=10, threshold=0.015)
    
    # ‚úÖ PASO CLAVE: Cargar trades reales como datos adicionales
    df_real = load_real_trades_as_labels(symbol=symbol, min_pnl_abs=1.0)
    
    X_real = pd.DataFrame()
    y_real = pd.Series(dtype='int')
    
    if not df_real.empty:
        print(f"‚ûï A√±adiendo {len(df_real)} trades reales al entrenamiento...")
        
        # ‚úÖ CREAR MAPPING PARA B√öSQUEDAS R√ÅPIDAS
        timestamp_to_index = {ts: idx for idx, ts in enumerate(df.index)}
        
        X_real_list = []
        y_real_list = []
        
        for _, trade in df_real.iterrows():
            try:
                trade_ts = trade['timestamp']
                if trade_ts in timestamp_to_index:
                    idx = timestamp_to_index[trade_ts]
                else:
                    # Buscar √≠ndice m√°s cercano
                    closest_idx = df.index.get_indexer([trade_ts], method='nearest')
                    idx = closest_idx[0]
                
                if 0 <= idx < len(df):
                    features = df.iloc[idx][feature_cols]
                    X_real_list.append(features)
                    y_real_list.append(trade['label'])
                else:
                    logging.warning(f"‚ö†Ô∏è √çndice inv√°lido {idx} para timestamp {trade_ts}")
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è Error procesando trade {trade.get('timestamp', 'N/A')}: {str(e)}")
        
        if X_real_list:
            X_real = pd.DataFrame(X_real_list, columns=feature_cols)
            y_real = pd.Series(y_real_list)
    
    # Combinar datos hist√≥ricos + reales
    if not X_real.empty:
        X = pd.concat([X, X_real], ignore_index=True)
        y = pd.concat([y, y_real], ignore_index=True)
        print(f"üìä Datos combinados: {len(X)} muestras ({len(X)-len(X_real)} hist√≥ricas + {len(X_real)} reales)")
    else:
        print(f"üìä Solo datos hist√≥ricos: {len(X)} muestras")
    
    if len(X) < 100:
        print("‚ùå Pocos datos para entrenar.")
        return
    
    # Dividir en train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # üí° ‚úÖ BALANCEO DE CLASES
    classes = np.array(sorted(set(y_train)))  # ‚úÖ CONVERTIR A NUMPY ARRAY
    class_weights = compute_class_weight('balanced', classes=classes, y=y_train)
    class_weight_dict = dict(zip(classes.tolist(), class_weights.tolist()))  # ‚úÖ Convertir de vuelta a lista para el dict
    print(f"‚öñÔ∏è Pesos de clases calculados: {class_weight_dict}")
    
    # üí° ‚úÖ PONDERACI√ìN POR IMPACTO (ROBUSTA)
    sample_weights = np.ones(len(X_train))

    if not X_real.empty:
        print("üìä Preparando ponderaci√≥n por impacto de trades...")
        
        # Identificar √≠ndices de trades reales en entrenamiento
        real_count = min(len(X_real), len(X_train))
        real_indices = np.arange(len(X_train) - real_count, len(X_train))
        
        if len(real_indices) > 0:
            print(f"  üîç Procesando {len(real_indices)} trades reales para ponderaci√≥n...")
            
            for i, idx in enumerate(real_indices):
                if idx >= len(sample_weights) or i >= len(df_real):
                    continue
                
                try:
                    # ‚úÖ EXTRAER PnL CON MANEJO DE ERRORES
                    trade = df_real.iloc[i]
                    pnl_value = None
                    
                    # Intentar diferentes nombres para el PnL
                    for pnl_key in ['pnl', 'PnL', 'profit', 'gain']:
                        if pnl_key in trade and pd.notna(trade[pnl_key]):
                            pnl_value = trade[pnl_key]
                            break
                    
                    # Valor por defecto si no se encuentra
                    if pnl_value is None:
                        logging.debug(f"‚ÑπÔ∏è Trade {i} sin PnL. Usando valor por defecto.")
                        pnl_value = 1.0  # Valor por defecto razonable
                    
                    # Asegurar que es num√©rico
                    if not isinstance(pnl_value, (int, float)):
                        pnl_value = float(str(pnl_value).replace(',', '.'))
                    
                    # Calcular peso
                    weight = max(0.1, abs(pnl_value))
                    sample_weights[idx] = weight
                    
                    # Logging para diagn√≥stico
                    if i < 5:  # Solo los primeros 5 para no saturar logs
                        logging.debug(f"  üìà Trade {i} | PnL: {pnl_value:.2f} | Peso: {weight:.2f}")
                        
                except Exception as e:
                    logging.warning(f"‚ö†Ô∏è Error en trade {i}: {str(e)}. Usando peso 0.5")
                    sample_weights[idx] = 0.5
            
            # Normalizar pesos
            min_weight = sample_weights.min()
            max_weight = sample_weights.max()
            if max_weight > min_weight:
                original_range = max_weight - min_weight
                sample_weights = 0.1 + 0.9 * (sample_weights - min_weight) / original_range
                print(f"  ‚úÖ Pesos normalizados: {min_weight:.2f} - {max_weight:.2f} ‚Üí 0.10 - 1.00")
            else:
                print(f"  ‚ÑπÔ∏è Todos los pesos son iguales ({min_weight:.2f}). Sin normalizaci√≥n necesaria.")
            
            print(f"  üìä Rango final de pesos: {sample_weights.min():.2f} - {sample_weights.max():.2f}")
    
    # Entrenar modelo
    print("üß† Entrenando Random Forest con clases balanceadas y ponderaci√≥n de impacto...")
    model = RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        random_state=42,
        class_weight=class_weight_dict,
        n_jobs=-1
    )
    model.fit(X_train, y_train, sample_weight=sample_weights)
    
    # Evaluar
    y_pred = model.predict(X_test)
    print("\n‚úÖ Resultados del modelo (CON BALANCEO Y PONDERACI√ìN):")
    print(classification_report(y_test, y_pred, target_names=['Short', 'Esperar', 'Long']))
    
    # Guardar modelo
    joblib.dump(model, 'ml_model.pkl')
    joblib.dump(feature_cols, 'feature_cols.pkl')
    print("\nüíæ Modelo guardado como 'ml_model.pkl'")

if __name__ == "__main__":
    symbol_to_use = "BTC/USDT" if TRADING_MODE == "spot" else "BTC/USDT:USDT"
    train_ml_model(symbol=symbol_to_use, days=1000)